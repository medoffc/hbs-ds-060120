{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "age = np.random.uniform(18, 65, 100)\n",
    "income = np.random.normal((age/10), 0.5)\n",
    "age = age.reshape(-1,1)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "fig.suptitle('age vs income', fontsize=16)\n",
    "plt.scatter(age, income)\n",
    "plt.plot(age, age/10, c='black')\n",
    "plt.xlabel('age', fontsize=14)\n",
    "plt.ylabel('monthly income', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Logistic regression model\n",
    "# Solver must be specified to avoid warning, see documentation for more information\n",
    "# liblinear is recommended for small datasets\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "regr = LogisticRegression(C=1e5, solver='liblinear')\n",
    "\n",
    "# Fit the model to the training set\n",
    "regr.fit(age, income_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the coefficients\n",
    "coef = regr.coef_\n",
    "interc = regr.intercept_\n",
    "\n",
    "# Create the linear predictor\n",
    "lin_pred = (age * coef + interc)\n",
    "\n",
    "# Perform the log transformation\n",
    "mod_income = 1 / (1 + np.exp(-lin_pred))\n",
    "\n",
    "# Sort the numbers to make sure plot looks right\n",
    "age_ordered, mod_income_ordered = zip(*sorted(zip(age ,mod_income.ravel()),key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "fig.suptitle('logistic regression', fontsize=16)\n",
    "plt.scatter(age, income_bin)\n",
    "plt.xlabel('age', fontsize=14)\n",
    "plt.ylabel('monthly income', fontsize=14)\n",
    "plt.plot(age_ordered, mod_income_ordered, c='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full logistic regression example: Using Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "relevant_columns2 = ['Pclass', 'Age', 'SibSp', 'Sex', 'Survived']\n",
    "dummy_dataframe2 = pd.get_dummies(df[relevant_columns2],drop_first=True,dtype=float)\n",
    "\n",
    "dummy_dataframe2.shape\n",
    "\n",
    "# Drop missing rows\n",
    "dummy_dataframe2 = dummy_dataframe2.dropna()\n",
    "dummy_dataframe2.shape\n",
    "\n",
    "# Split the data into X and y\n",
    "y = dummy_dataframe2.Survived\n",
    "X = dummy_dataframe2.drop(columns=['Survived'], axis=1)\n",
    "\n",
    "# Build a logistic regression model using statsmodels\n",
    "import statsmodels as sm\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "# Create intercept term required for sm.Logit, see documentation for more information\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "logit_model = sm.Logit(y, X)\n",
    "\n",
    "# Get results of the fit\n",
    "results = logit_model.fit()\n",
    "\n",
    "# Summary table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full logistic regression example: Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "X = X.fillna(value=0) \n",
    "for col in X.columns:\n",
    "    # Subtract the minimum and divide by the range forcing a scale of 0 to 1 for each feature\n",
    "    X[col] = (X[col] - min(X[col]))/ (max(X[col]) - min(X[col])) \n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# We could subtract the two columns. If values or equal, difference will be zero. Then count number of zeros \n",
    "residuals = np.abs(y_train - y_hat_train)\n",
    "print(pd.Series(residuals).value_counts())\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.abs(y_test - y_hat_test)\n",
    "print(pd.Series(residuals).value_counts())\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing pretty metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made something for y'all\n",
    "\n",
    "def eval_classification(model, model_name,\n",
    "                        X_tr, X_te, y_tr, y_te,\n",
    "                        to_print=False):\n",
    "    '''\n",
    "    Finds predictions for train and test sets, then\n",
    "    prints metrics for classification nicely\n",
    "\n",
    "    Inputs:\n",
    "    model : already-fit sklearn model\n",
    "    model_name : string, name for index for output df\n",
    "    X_tr : training X (can be scaled, that's fine)\n",
    "    X_te : testing X\n",
    "    y_tr : training target\n",
    "    y_te : testing target\n",
    "    to_print : boolean, will print output nicely if True\n",
    "\n",
    "    Outputs:\n",
    "    metric_df - pandas Dataframe showing output\n",
    "    '''\n",
    "    \n",
    "    metrics = {\"Accuracy\": accuracy_score,\n",
    "               \"Recall\": recall_score,\n",
    "               \"Precision\": precision_score,\n",
    "               \"F1-Score\": f1_score}\n",
    "\n",
    "    y_pred_tr = model.predict(X_tr)\n",
    "    y_pred_te = model.predict(X_te)\n",
    "\n",
    "    # Defining the column names based on the metric dict keys\n",
    "    col_list = []  # Starting a list\n",
    "    for name in metrics.keys():\n",
    "        col_list.append(f\"{name.lower()}_train\")\n",
    "        col_list.append(f\"{name.lower()}_test\")\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=col_list)\n",
    "\n",
    "    for name, metric_function in metrics.items():\n",
    "        tr_col = f\"{name.lower()}_train\"\n",
    "        metric_df.at[model_name, tr_col] = metric_function(y_tr, y_pred_tr)\n",
    "        te_col = f\"{name.lower()}_test\"\n",
    "        metric_df.at[model_name, te_col] = metric_function(y_te, y_pred_te)\n",
    "        \n",
    "        # Adding to-print option to print the metrics nicely\n",
    "        if to_print:\n",
    "            print(f\"{name}:\"); print(\"=\"*len(name))\n",
    "            print(f\"TRAIN: {metric_function(y_tr, y_pred_tr):.4f}\")\n",
    "            print(f\"TEST: {metric_function(y_te, y_pred_te):.4f}\")\n",
    "            print(\"*\" * 15)\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our predefined function\n",
    "logreg_scores = eval_classification(logreg, \"logreg\",\n",
    "                                    X_train_sc, X_test_sc,\n",
    "                                    y_train, y_test,\n",
    "                                    to_print=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
